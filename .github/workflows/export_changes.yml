name: Export Changes

on:
  workflow_call:
    inputs:
      bucket_name:
        required: true
        type: string
      aws_region:
        required: true
        type: string
      include_code:
        required: false
        type: string
        default: ''
      include_documentation:
        required: false
        type: string
        default: ''
      exclude_code:
        required: false
        type: string
        default: ''
      exclude_documentation:
        required: false
        type: string
        default: ''
    secrets:
      AWS_ACCESS_KEY_ID:
        required: true
      AWS_SECRET_ACCESS_KEY:
        required: true

jobs:
  export-structure:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
        with:
          fetch-depth: 0

      - name: Set GitHub Variables
        run: |
          COMMIT_ID="${GITHUB_SHA}"
          
          # Ensure we have a commit SHA
          if [[ -z "$COMMIT_ID" ]]; then
            echo "No commit SHA found. Using latest commit from main branch."
            COMMIT_ID=$(git rev-parse HEAD)
          fi
          
          # Get commit date in YYYY/MM/DD format
          COMMIT_DATE=$(git show -s --format=%cd --date=format:'%Y/%m/%d' "$COMMIT_ID")
          echo "COMMIT_ID=$COMMIT_ID" >> $GITHUB_ENV
          echo "COMMIT_DATE=$COMMIT_DATE" >> $GITHUB_ENV
          
          BASE_S3_PATH="s3://${{ vars.BUCKET_NAME }}/${{ github.event.repository.name }}"
          echo "BASE_S3_PATH=$BASE_S3_PATH" >> $GITHUB_ENV

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ inputs.aws_region }}

      - name: Upload filtered code and documentation to S3
        run: |
          set -e

          # Inputs
          CODE_INCLUDE="${{ inputs.include_code }}"
          CODE_EXCLUDE="${{ inputs.exclude_code }}"
          DOC_INCLUDE="${{ inputs.include_documentation }}"
          DOC_EXCLUDE="${{ inputs.exclude_documentation }}"

          # Funzione che identifica se un path è incluso
          should_include() {
            local path="$1"
            local includes="$2"
            local excludes="$3"

            # Se è nella lista di esclusione → salta
            for item in ${excludes//,/ }; do
              item=$(echo "$item" | xargs)  # trim
              if [[ "$item" == .* && "$path" == *"$item" ]]; then
                return 1
              elif [[ "$item" != .* && "$path" == "$item" ]]; then
                return 1
              elif [[ "$item" != .* && "$path" == "$item/"* ]]; then
                return 1
              fi
            done

            # Se include è vuoto → includi tutto
            if [[ -z "$includes" ]]; then
              return 0
            fi

            # Se è nella lista di inclusione → accetta
            for item in ${includes//,/ }; do # per ogni elemento della lista
              item=$(echo "$item" | xargs)  # trim, rimuove spazi iniziali e finali
              if [[ "$item" == .* && "$path" == *"$item" ]]; then
                return 0
              elif [[ "$item" != .* && "$path" == "$item" ]]; then
                return 0
              elif [[ "$item" != .* && "$path" == "$item/"* ]]; then
                return 0
              fi
            done

            return 1  # Altrimenti scarta
          }

          # Funzione che esegue l’upload dei file in base alla logica sopra
          upload_filtered() {
            local dest="$1"
            local includes="$2"
            local excludes="$3"

            echo "🔍 Scanning files for $dest..."
            find . -type f | while read file; do
              clean_path="${file#./}" # Rimuove il prefisso "./" dai percorsi
              if should_include "$clean_path" "$includes" "$excludes"; then
                echo "✅ Upload: $clean_path → $dest/$clean_path"
                aws s3 cp "$file" "$BASE_S3_PATH/$dest/$clean_path"
              else
                echo "⏭️ Skipped: $clean_path"
              fi
            done
          }

          echo "🧹 Cleaning S3 destinations..."
          aws s3 rm "$BASE_S3_PATH/code/" --recursive || true
          aws s3 rm "$BASE_S3_PATH/documentation/" --recursive || true

          echo "🚀 Uploading CODE..."
          upload_filtered "code" "$CODE_INCLUDE" "$CODE_EXCLUDE"

          echo "📄 Uploading DOCUMENTATION..."
          upload_filtered "documentation" "$DOC_INCLUDE" "$DOC_EXCLUDE"

      - name: Generate repository structure
        run: |
          git ls-tree -r --name-only HEAD > repo_structure_${{ env.COMMIT_ID }}.txt  

      - name: Upload repository structure as artifact
        uses: actions/upload-artifact@v4
        with:
          name: repository-structure
          path: repo_structure_${{ env.COMMIT_ID }}.txt

      - name: Generate commit history
        run: |
          echo "Hash,Author,Date,Message" > commit-history.csv
          git log --pretty=format:"%H,%an,%ai,%s" >> commit-history.csv

      - name: Upload commit history as artifact
        uses: actions/upload-artifact@v4
        with:
          name: commit-history
          path: commit-history.csv

      - name: Extract diff of the commit
        run: |
          commit_id=$COMMIT_ID
          git diff $commit_id^ > diff_${commit_id}.txt

      - name: Save diff as artifact
        uses: actions/upload-artifact@v4
        with:
          name: commit-diff
          path: diff_${{ env.COMMIT_ID }}.txt

      - name: Upload Commit History to S3
        run: |
          aws s3 cp commit-history.csv $BASE_S3_PATH/codeChanges/commit-history.csv

      - name: Upload Repository Structure and Commit diff to S3 in YYYY/MM/DD Subfolder
        run: |
            aws s3 cp repo_structure_${{ env.COMMIT_ID }}.txt $BASE_S3_PATH/codeChanges/$COMMIT_DATE/repo_structure_${{ env.COMMIT_ID }}.txt
            aws s3 cp diff_${{ env.COMMIT_ID }}.txt $BASE_S3_PATH/codeChanges/$COMMIT_DATE/diff_${{ env.COMMIT_ID }}.txt
