name: Export Changes

on:
  workflow_call:
    inputs:
      bucket_name:
        required: true
        type: string
      aws_region:
        required: true
        type: string
      include_code:
        required: false
        type: string
        default: ''
      include_documentation:
        required: false
        type: string
        default: ''
      exclude_code:
        required: false
        type: string
        default: ''
      exclude_documentation:
        required: false
        type: string
        default: ''
    secrets:
      AWS_ACCESS_KEY_ID:
        required: true
      AWS_SECRET_ACCESS_KEY:
        required: true

jobs:
  export-structure:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
        with:
          fetch-depth: 0

      - name: Set GitHub Variables
        run: |
          COMMIT_ID="${GITHUB_SHA}"
          
          # Ensure we have a commit SHA
          if [[ -z "$COMMIT_ID" ]]; then
            echo "No commit SHA found. Using latest commit from main branch."
            COMMIT_ID=$(git rev-parse HEAD)
          fi
          
          # Get commit date in YYYY/MM/DD format
          COMMIT_DATE=$(git show -s --format=%cd --date=format:'%Y/%m/%d' "$COMMIT_ID")
          echo "COMMIT_ID=$COMMIT_ID" >> $GITHUB_ENV
          echo "COMMIT_DATE=$COMMIT_DATE" >> $GITHUB_ENV
          
          BASE_S3_PATH="s3://${{ inputs.bucket_name }}/${{ github.event.repository.name }}"
          echo "BASE_S3_PATH=$BASE_S3_PATH" >> $GITHUB_ENV

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ inputs.aws_region }}

      - name: Sync of code and documentation to S3
        run: |
          set -e

          to_patterns() {
            local input="$1"
            local flag="$2"
            local -a patterns=()
            IFS=',' read -ra ITEMS <<< "$input"
            for item in "${ITEMS[@]}"; do
              item=$(echo "$item" | xargs)
              [[ -z "$item" ]] && continue
          
              if [[ "$item" == .?* ]]; then  # es: .git, .md
                if [[ "$item" == */ ]]; then
                  patterns+=("$flag" "${item%/}")
                  patterns+=("$flag" "${item%/}/*")
                else
                  patterns+=("$flag" "*$item")
                fi
              elif [[ "$item" == */ ]]; then
                patterns+=("$flag" "${item%/}")
                patterns+=("$flag" "${item%/}/*")
              elif [[ "$item" == *.* ]]; then
                patterns+=("$flag" "*$item")
              else
                patterns+=("$flag" "$item")
                patterns+=("$flag" "$item/*")
              fi
            done
            echo "${patterns[@]}"
          }

          CODE_INCLUDE="${{ inputs.include_code }}"
          CODE_EXCLUDE="${{ inputs.exclude_code }}"
          DOC_INCLUDE="${{ inputs.include_documentation }}"
          DOC_EXCLUDE="${{ inputs.exclude_documentation }}"

          # Code sync
          if [[ -z "$CODE_INCLUDE" ]]; then
            read -ra EXCLUDE_ARGS <<< "$(to_patterns "$CODE_EXCLUDE" --exclude)"
            echo "ðŸš€ Syncing all code files except excluded..."
            aws s3 sync . "$BASE_S3_PATH/code/" \
              --dryrun \
              "${EXCLUDE_ARGS[@]}" \
              --delete
          else
            read -ra INCLUDE_ARGS <<< "$(to_patterns "$CODE_INCLUDE" --include)"
            read -ra EXCLUDE_ARGS <<< "$(to_patterns "$CODE_EXCLUDE" --exclude)"
            echo "ðŸš€ Syncing filtered code files..."
            aws s3 sync . "$BASE_S3_PATH/code/" \
              --dryrun \  
              --exclude "*" \
              "${INCLUDE_ARGS[@]}" \
              "${EXCLUDE_ARGS[@]}" \
              --delete
          fi

          # Documentation sync
          if [[ -z "$DOC_INCLUDE" ]]; then
            read -ra EXCLUDE_ARGS <<< "$(to_patterns "$DOC_EXCLUDE" --exclude)"
            echo "ðŸš€ Syncing all documentation files except excluded..."
            aws s3 sync . "$BASE_S3_PATH/documentation/" \
              --dryrun \
              "${EXCLUDE_ARGS[@]}" \
              --delete
          else
            read -ra INCLUDE_ARGS <<< "$(to_patterns "$DOC_INCLUDE" --include)"
            read -ra EXCLUDE_ARGS <<< "$(to_patterns "$DOC_EXCLUDE" --exclude)"
            echo "ðŸš€ Syncing filtered documentation files..."
           aws s3 sync . "$BASE_S3_PATH/documentation/" \
            --dryrun \
            --exclude "*" \
            "${INCLUDE_ARGS[@]}" \
            "${EXCLUDE_ARGS[@]}" \
            --delete
          fi

      - name: Generate repository structure
        run: |
          git ls-tree -r --name-only HEAD > repo_structure_${{ env.COMMIT_ID }}.txt  

      - name: Upload repository structure as artifact
        uses: actions/upload-artifact@v4
        with:
          name: repository-structure
          path: repo_structure_${{ env.COMMIT_ID }}.txt

      - name: Generate commit history
        run: |
          echo "Hash,Author,Date,Message" > commit-history.csv
          git log --pretty=format:"%H,%an,%ai,%s" >> commit-history.csv

      - name: Upload commit history as artifact
        uses: actions/upload-artifact@v4
        with:
          name: commit-history
          path: commit-history.csv

      - name: Extract diff of the commit
        run: |
          commit_id=$COMMIT_ID
          git diff $commit_id^ > diff_${commit_id}.txt

      - name: Save diff as artifact
        uses: actions/upload-artifact@v4
        with:
          name: commit-diff
          path: diff_${{ env.COMMIT_ID }}.txt

      - name: Upload Commit History to S3
        run: |
          aws s3 cp commit-history.csv $BASE_S3_PATH/codeChanges/commit-history.csv

      - name: Upload Repository Structure and Commit diff to S3 in YYYY/MM/DD Subfolder
        run: |
            aws s3 cp repo_structure_${{ env.COMMIT_ID }}.txt $BASE_S3_PATH/codeChanges/$COMMIT_DATE/repo_structure_${{ env.COMMIT_ID }}.txt
            aws s3 cp diff_${{ env.COMMIT_ID }}.txt $BASE_S3_PATH/codeChanges/$COMMIT_DATE/diff_${{ env.COMMIT_ID }}.txt
